Wed Aug 20 16:35:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:D8:00.0 Off |                    0 |
| N/A   32C    P0             36W /  250W |       1MiB /  32768MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Using device: cuda
Loading standard tokenizer ('bert-base-uncased')...
Standard vocabulary size: 30522
PAD token ID: 0
Instantiated Base Model: TinyQA with 4,336,384 trainable parameters.
Best pre-trained model will be saved to: models/date_20250820-163534/toy_llm_unified_pretrained.pth

--- Starting CLM Pre-training on nq_open ---
--- End of Pre-train Epoch 1 | Train Loss: 6.1267 | Validation Loss: 5.6458 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 2 | Train Loss: 5.3179 | Validation Loss: 5.3817 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 3 | Train Loss: 5.0433 | Validation Loss: 5.2819 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 4 | Train Loss: 4.8754 | Validation Loss: 5.2113 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 5 | Train Loss: 4.7582 | Validation Loss: 5.1727 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 6 | Train Loss: 4.6699 | Validation Loss: 5.1545 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 7 | Train Loss: 4.5991 | Validation Loss: 5.1305 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 8 | Train Loss: 4.5421 | Validation Loss: 5.1117 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 9 | Train Loss: 4.4942 | Validation Loss: 5.1041 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 10 | Train Loss: 4.4527 | Validation Loss: 5.0980 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 11 | Train Loss: 4.4160 | Validation Loss: 5.0996 | LR: 0.000299 ---
--- End of Pre-train Epoch 12 | Train Loss: 4.3837 | Validation Loss: 5.0892 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 13 | Train Loss: 4.3570 | Validation Loss: 5.0863 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 14 | Train Loss: 4.3341 | Validation Loss: 5.0907 | LR: 0.000299 ---
--- End of Pre-train Epoch 15 | Train Loss: 4.3133 | Validation Loss: 5.0897 | LR: 0.000299 ---
--- End of Pre-train Epoch 16 | Train Loss: 4.2950 | Validation Loss: 5.0845 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 17 | Train Loss: 4.2797 | Validation Loss: 5.0839 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 18 | Train Loss: 4.2636 | Validation Loss: 5.0830 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 19 | Train Loss: 4.2529 | Validation Loss: 5.0905 | LR: 0.000299 ---
--- End of Pre-train Epoch 20 | Train Loss: 4.2424 | Validation Loss: 5.0916 | LR: 0.000299 ---
--- End of Pre-train Epoch 21 | Train Loss: 4.2328 | Validation Loss: 5.0823 | LR: 0.000299 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 22 | Train Loss: 4.2241 | Validation Loss: 5.0899 | LR: 0.000299 ---
--- End of Pre-train Epoch 23 | Train Loss: 4.2175 | Validation Loss: 5.0832 | LR: 0.000299 ---
--- End of Pre-train Epoch 24 | Train Loss: 4.2099 | Validation Loss: 5.0869 | LR: 0.000299 ---
--- End of Pre-train Epoch 25 | Train Loss: 4.0297 | Validation Loss: 5.0549 | LR: 0.000150 ---
Validation loss improved. Saving model to models/date_20250820-163534/toy_llm_unified_pretrained.pth
--- End of Pre-train Epoch 26 | Train Loss: 3.9894 | Validation Loss: 5.0623 | LR: 0.000150 ---
--- End of Pre-train Epoch 27 | Train Loss: 3.9768 | Validation Loss: 5.0712 | LR: 0.000150 ---
--- End of Pre-train Epoch 28 | Train Loss: 3.9712 | Validation Loss: 5.0749 | LR: 0.000150 ---
--- End of Pre-train Epoch 29 | Train Loss: 3.8628 | Validation Loss: 5.0637 | LR: 0.000075 ---
--- End of Pre-train Epoch 30 | Train Loss: 3.8428 | Validation Loss: 5.0704 | LR: 0.000075 ---

Early stopping triggered after 5 epochs without improvement.

Loading best pretrained model from models/date_20250820-163534/toy_llm_unified_pretrained.pth

Testing prompt completion after pretraining:
Prompt: 'The capital of France is'
Model completion: the capital of france is caused by what us rajasthan

--- Starting Fine-tuning on QA-SRL ---
Successfully loaded pre-trained weights into the QA model.
Loading and processing qa_srl dataset for 'train' split...
