============================================
Starting job: TinyQA_1214
Model size: tiny
Date: Sun 14 Dec 02:52:44 GMT 2025
============================================
Sun Dec 14 02:52:45 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:58:00.0 Off |                    0 |
| N/A   33C    P0             23W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Starting Python script for TinyQA model...
--- Loaded configuration 'tiny' from '/home/zceccgr/Scratch/freezeLLM/llm_scale_up/config.json' ---
Using device: cuda
Loading standard tokenizer ('bert-base-uncased')...
Standard vocabulary size: 30522
PAD token ID: 0
Instantiated Base Model: TinyQA with 4,336,384 trainable parameters.
Best pre-trained model will be saved to: models/TinyQA_20251214-025258/toy_llm_unified_pretrained.pth

--- Starting CLM Pre-training on nq_open for 'TinyQA' model ---
Pre-training batch size: 16 | Gradient accumulation: 2 | Effective batch size: 32
============================================
Job completed: Sun 14 Dec 02:55:23 GMT 2025
============================================
